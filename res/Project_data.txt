## 기술 면접관 포트폴리오 분석 보고서

**지원자:** 이준호 (AI 엔지니어 지원)
**분석 일자:** 2024년 6월 10일
**평가 목적:** 포트폴리오 프로젝트 수행 능력 및 기술적 숙련도 검증

---

### 종합 분석 의견

이준호 지원자는 데이터 수집/전처리부터 최신 딥러닝 모델 적용 및 평가까지 AI 엔지니어링의 전반적인 파이프라인에 대한 실질적인 경험을 갖추고 있습니다. 특히, **자연어 처리(NLP)** 분야에서 뛰어난 깊이를 보여주며, 한국어 데이터 처리를 위한 KoNLPy, SKT-BERT, ratsnlp 등 전문적인 라이브러리와 Transformer 기반 모델 사용에 능숙합니다.

프로젝트 포트폴리오는 추천 시스템, 음성 인식, 텍스트 분류 등 다양한 영역을 포괄하며, 문제 해결 시 전통적인 ML 기법과 최신 딥러닝 아키텍처를 적절히 조합하는 하이브리드 접근 방식을 잘 활용합니다. 전반적인 기술적 숙련도는 **높음**으로 판단됩니다.

---

### 1. 프로젝트 개요 (Project Overview)

지원자는 총 4가지 주요 AI 프로젝트를 제시했습니다. 각 프로젝트는 데이터 수집/가공부터 모델 학습 및 평가까지의 전체 과정을 포함하며, 각기 다른 AI 도메인을 다루고 있어 폭넓은 경험을 입증합니다.

| No. | 프로젝트명 | 주요 목표 | 도메인 |
| :---: | :--- | :--- | :--- |
| 1 | 북추 - 연계 독서 AI 도서추천 서비스 | 사용자의 연계 독서를 위한 3가지 방식의 하이브리드 도서 추천 | 추천 시스템 (NLP, Matrix Factorization) |
| 2 | 음성 특징 구분 모델 | 사람 음성 데이터의 성별 및 나이대 분류 | 음성 인식 (CNN 기반 이미지 분류) |
| 3 | 허위소문 (虛僞所聞) - 뉴스 신뢰도 분석 서비스 | 자극적인 기사를 선별하는 뉴스 신뢰도 분석 (낚시성 기사 탐지) | 텍스트 이진 분류 (NLP) |
| 4 | 국민청원 카테고리 재분류 | 정책적 변화에 맞춘 기존 청원 카테고리 다중 분류 | 텍스트 다중 분류 (NLP) |

### 2. 사용 기술 (Technologies Used)

지원자는 파이썬 환경 내에서 데이터 처리, 머신러닝, 딥러닝, 그리고 전문 NLP 영역에 걸쳐 폭넓은 기술 스택을 활용했습니다.

| 구분 | 주요 기술 항목 | 특이 사항 및 평가 |
| :--- | :--- | :--- |
| **핵심 언어 및 데이터 처리** | Python, Pandas, Numpy, SQL | 기본 데이터 처리 역량은 매우 안정적임. |
| **딥러닝 프레임워크** | TensorFlow, Keras, PyTorch | 두 가지 주요 프레임워크 모두 사용 경험이 있어 환경 전환 및 유연한 모델 개발이 가능함. |
| **NLP/추천 전문 기술** | KoNLPy, Transformer (S-BERT, SKT-BERT), FAISS, GPT (OpenAPI) | 한국어 NLP에 특화된 라이브러리 (KoNLPy, SKT-BERT)를 활용했으며, 임베딩 벡터의 효율적인 유사도 검색을 위한 FAISS를 사용한 점은 기술적 깊이가 있음을 시사함. GPT를 키워드 추출에 활용한 점은 최신 기술의 통합 능력을 보여줌. |
| **데이터 수집 및 기타** | Web Crawling (BeautifulSoup), Open API, Librosa, OpenCV | 데이터 확보 및 가공 능력이 우수하며, 음성 처리(Librosa) 및 시각 처리(OpenCV)에 대한 경험도 확인됨. |

### 3. 기여도 (Contribution)

지원자는 프로젝트의 **데이터 파이프라인 구축 및 핵심 모델 개발**에 주도적으로 기여한 것으로 보입니다.

*   **데이터 구축 주도:** '북추' 프로젝트에서 알라딘, 네이버, 도서관 정보나루 API 및 웹 크롤링을 활용하여 10만 건 이상의 데이터를 직접 구축했습니다 (Data 1). '허위소문' 프로젝트에서도 73만 건의 낚시성 기사 데이터를 처리했습니다. 이는 데이터 확보 및 대규모 전처리 역량이 높음을 의미합니다.
*   **다중 모델 설계:** '북추' 서비스에서 KNN, LDA/FAISS, Matrix Factorization, S-BERT 기반 키워드 추천 등 3가지 AI 서비스 아키텍처를 모두 설계하고 구현한 것으로 보아, 프로젝트 전반의 핵심 설계 및 구현을 담당했습니다.
*   **최신 기술 적용:** 각 프로젝트에서 해당 도메인의 SOTA(State-of-the-Art) 모델(예: Transformer, BERT)을 선택하여 적용하고, 성능 수치(ROC-AUC 0.91~0.93, Accuracy 88%)를 명확히 제시한 것은 주도적인 개발 역량을 나타냅니다.

### 4. 문제 해결 (Problem Solving)

지원자는 각 도메인의 특성에 맞는 기술적 난관을 해결하기 위해 합리적인 방법을 선택했습니다.

| 프로젝트 | 문제 해결 전략 | 평가 |
| :--- | :--- | :--- |
| **북추** | 이질적인 데이터(구조화/비구조화) 통합 및 효율적 유사도 검색 | **문제:** 다양한 출처의 데이터를 통일된 추천 시스템으로 통합해야 함. **해결:** 텍스트 데이터에는 LDA와 S-BERT 임베딩을 사용하고, 수치형/범주형 데이터에는 KNN과 MF를 사용하여 하이브리드 추천을 구현. 특히 대규모 벡터 검색을 위해 FAISS를 도입한 것은 효율성을 고려한 접근임. |
| **음성 특징 구분 모델** | 비정형 음성 데이터의 이미지 변환 | **문제:** 시계열 음성 데이터를 딥러닝 모델에 효과적으로 학습시켜야 함. **해결:** `librosa`를 사용하여 wav 파일을 시간-주파수 도메인의 Spectrogram 이미지로 변환하여 CNN 모델의 입력으로 활용. 이는 음성 특징 추출에 있어 표준적이면서도 강력한 기법을 정확하게 적용한 사례임. |
| **허위소문 / 국민청원** | 복잡하고 모호한 한국어 텍스트 분류 | **문제:** 한국어의 높은 복잡성과 문맥 의존성을 가진 텍스트를 정확하게 분류해야 함. **해결:** KoNLPy를 통한 정교한 형태소 분석 및 불용어 처리 후, SKT-BERT/S-BERT와 같은 Transformer 기반의 대규모 언어 모델을 파인튜닝하여 분류 성능을 높임. |

### 5. 기술적 숙련도 (Technical Proficiency)

지원자의 기술적 숙련도는 다음과 같이 평가됩니다.

**① Deep Learning 및 MLOps 이해:**
*   CNN(음성), Transformer(텍스트 분류), Matrix Factorization(추천) 등 다양한 아키텍처를 구현하고 평가한 경험이 있습니다.
*   프로젝트 전반에서 Web Crawling, API 활용, 그리고 결과물 산출(퍼센테이지, 웹 서비스 스크린샷)을 제시한 것은 실제 서비스 환경을 고려한 **MLOps 초기 단계의 이해도**를 보여줍니다.

**② NLP 특화 역량 (가장 높은 숙련도):**
*   단순 토크나이징을 넘어, `KoNLPy`를 활용한 형태소 분석 및 불용어 제거 등 한국어 텍스트 전처리 과정에 대한 깊은 이해를 보여줍니다.
*   S-BERT를 이용한 임베딩, 코사인 유사도 측정, FAISS를 통한 고속 검색 능력은 텍스트 데이터 기반의 검색 및 추천 시스템 설계에 즉시 투입 가능한 수준입니다.

**③ 결과 및 검증 지향성:**
*   모든 프로젝트에서 ROC-AUC, Accuracy, 만족도 95% 달성 등의 정량적 지표를 제시했습니다. 이는 단순히 모델을 구현하는 것을 넘어, **모델의 성능 검증 및 개선**에 중점을 둔 개발 태도를 보여줍니다.

**종합 평가:**

이준호 지원자는 기본적인 데이터 사이언스 역량(자격증 포함) 위에 최신 딥러닝 기술, 특히 NLP 분야의 전문 지식을 효과적으로 활용할 수 있는 실무 능력을 갖추고 있습니다. 포트폴리오의 내용과 결과물은 지원자가 AI 엔지니어링 직무를 성공적으로 수행할 수 있음을 강력하게 시사합니다.

---
*(면접 시 질문할 내용: GPT 2.4 Turbo Model을 키워드 추출에 사용한 구체적인 방식과 비용 효율성에 대해 추가 질문 필요. 또한, 북추 프로젝트에서 3가지 추천 결과를 어떻게 가중치로 통합하여 최종 결과를 도출했는지에 대한 상세한 설명 요청 필요.)*